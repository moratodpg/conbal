{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy.stats import kruskal, norm\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple recursive approach\n",
    "def compute_AALC(d):\n",
    "    if 'accuracy_test' in d:\n",
    "        acc_list = d['accuracy_test']\n",
    "        d['aalc'] = np.mean(acc_list)\n",
    "    else:\n",
    "        for v in d.values():\n",
    "            compute_AALC(v)\n",
    "    return d\n",
    "\n",
    "## Rank experiments based on AALC\n",
    "def rank_experiments(d, config):\n",
    "    results = []\n",
    "    for strategy, strategy_data in d[config].items():\n",
    "        for acquisition, acquisition_data in strategy_data.items():\n",
    "            for budget, budget_data in acquisition_data.items():\n",
    "                for seed, seed_data in budget_data.items():\n",
    "                    aalc = seed_data.get('aalc')\n",
    "                    if aalc is not None:\n",
    "                        name = f\"{strategy}_{acquisition}_{budget}_{seed}\"\n",
    "                        results.append((name, aalc))\n",
    "    # Sort by aalc descending\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def get_average_ranks_group(loaded, config):\n",
    "    # 1) Flatten and rank all (experiment+seed) pairs\n",
    "    flat = []\n",
    "    for strategy in loaded[config]:\n",
    "        for acquisition in loaded[config][strategy]:\n",
    "            for budget in loaded[config][strategy][acquisition]:\n",
    "                for seed, data in loaded[config][strategy][acquisition][budget].items():\n",
    "                    key = f\"{strategy}_{acquisition}_{budget}_{seed}\"\n",
    "                    flat.append((key, data['aalc']))\n",
    "\n",
    "    # sort by descending AALC, assign global rank 1…N\n",
    "    flat_sorted = sorted(flat, key=lambda x: x[1], reverse=True)\n",
    "    flat_ranks = { name: rank\n",
    "                for rank, (name, _) in enumerate(flat_sorted, start=1) }\n",
    "\n",
    "    # 2) Group by experiment (without seed) and average those ranks\n",
    "    groups = defaultdict(list)\n",
    "    for name, rank in flat_ranks.items():\n",
    "        # remove the final \"_seed\" suffix\n",
    "        exp_base = name.rsplit('_', 1)[0]\n",
    "        groups[exp_base].append(rank)\n",
    "\n",
    "    avg_ranks = [(exp, np.mean(ranks)) for exp, ranks in groups.items()]\n",
    "    avg_ranks_sorted = sorted(avg_ranks, key=lambda x: x[1])\n",
    "\n",
    "    # === Print results ===\n",
    "    print(\"=== Global ranks (experiment_seed) ===\")\n",
    "    for name, aalc in flat_sorted[:10]:  # top 10 for example\n",
    "        print(f\"{name:30s}  aalc={aalc:.4f}, rank={flat_ranks[name]}\")\n",
    "\n",
    "    print(\"\\n=== Average rank per experiment ===\")\n",
    "    for exp, avg in avg_ranks_sorted:\n",
    "        print(f\"{exp:30s}  avg_rank={avg:.2f}\")\n",
    "\n",
    "    return groups, flat\n",
    "\n",
    "def calculate_krusal(groups):\n",
    "    rank_per_group = list(groups.values())\n",
    "    group_names    = list(groups.keys())\n",
    "\n",
    "    print(\"=== Kruskal–Wallis test ===\")\n",
    "    for i, (name, ranks) in enumerate(zip(group_names, rank_per_group), 1):\n",
    "        print(f\"Group {i} ({name}): {ranks}\")\n",
    "    H, p = kruskal(*rank_per_group)\n",
    "    print(f\"\\nKruskal–Wallis H = {H:.3f}, p = {p:.3f}\")\n",
    "\n",
    "def calculate_posthoc(groups):\n",
    "    # ----- Kruskal‑Wallis (global test) -----\n",
    "    values = np.concatenate(list(groups.values()))\n",
    "    labels = np.concatenate([[name]*len(vals) for name, vals in groups.items()])\n",
    "    grouped_values = [np.array(groups[name]) for name in groups]\n",
    "    kw_stat, kw_p = stats.kruskal(*grouped_values)\n",
    "    print(f\"\\nKruskal-Wallis test: H = {kw_stat:.3f}, p = {kw_p:.3f}\")\n",
    "\n",
    "    # ----- Dunn's test (post-hoc) -----\n",
    "    N = len(values)\n",
    "    V = N*(N+1)/12  # rank variance\n",
    "    # Rank all observations\n",
    "    ranks = stats.rankdata(values, method='average')\n",
    "    # Map ranks to groups\n",
    "    rank_groups = {name: ranks[labels == name] for name in groups}\n",
    "    mean_ranks = {name: r.mean() for name, r in rank_groups.items()}\n",
    "    n_i = {name: len(vals) for name, vals in groups.items()}\n",
    "\n",
    "    names = list(groups.keys())\n",
    "    m = len(names)\n",
    "    p_raw = []\n",
    "    pairs = []\n",
    "    # Pairwise Z and p\n",
    "    for i in range(m):\n",
    "        for j in range(i+1, m):\n",
    "            ni, nj = n_i[names[i]], n_i[names[j]]\n",
    "            denom = np.sqrt(V * (1/ni + 1/nj))\n",
    "            z = abs(mean_ranks[names[i]] - mean_ranks[names[j]]) / denom\n",
    "            p = 2 * (1 - norm.cdf(z))\n",
    "            pairs.append((names[i], names[j]))\n",
    "            p_raw.append(p)\n",
    "\n",
    "    # Holm correction\n",
    "    p_adj = multipletests(p_raw, method='holm')[1]\n",
    "\n",
    "    # Build adjusted p‑value matrix\n",
    "    adj_matrix = np.full((m, m), np.nan)\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "        for j in range(i+1, m):\n",
    "            adj_matrix[i, j] = p_adj[k]\n",
    "            adj_matrix[j, i] = p_adj[k]\n",
    "            k += 1\n",
    "\n",
    "    df_adj = pd.DataFrame(adj_matrix, index=names, columns=names)\n",
    "    print(\"\\n=== Dunn's test (post-hoc) ===\")\n",
    "    print(\"Pairwise adjusted p-values:\")\n",
    "    print(df_adj.round(3))\n",
    "\n",
    "    return df_adj, mean_ranks\n",
    "\n",
    "def get_categories(df_adj):\n",
    "    print(\"\\n=== Dunn's test (post-hoc) ===\")\n",
    "    print(\"Pairwise adjusted p-values:\")\n",
    "    # create a boolean mask for the upper triangle\n",
    "    mask = np.triu(np.ones(df_adj.shape), k=1).astype(bool)\n",
    "\n",
    "    # stack only those entries, then filter\n",
    "    sig_df = (\n",
    "        df_adj.where(mask)\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={'level_0':'Group1', 'level_1':'Group2', 0:'p_adj'})\n",
    "            .query('p_adj < 0.05')\n",
    "    )\n",
    "    print(sig_df)\n",
    "\n",
    "def sort_methods(df_adj, mean_ranks, alpha=0.05):\n",
    "    # alpha = 0.05\n",
    "\n",
    "    # sort methods from best (lowest rank) to worst (highest rank)\n",
    "    methods = sorted(mean_ranks, key=lambda m: mean_ranks[m])\n",
    "\n",
    "    # container for letter assignments\n",
    "    letter_groups = {}\n",
    "    current_letter = ord('A')\n",
    "\n",
    "    for m in methods:\n",
    "        # try to fit m into an existing letter\n",
    "        for letter in sorted(set(letter_groups.values())):\n",
    "            group_mates = [mm for mm, lt in letter_groups.items() if lt == letter]\n",
    "            # check that m is NOT significantly different from *any* of these\n",
    "            if all(df_adj.loc[m, mm] > alpha for mm in group_mates):\n",
    "                letter_groups[m] = letter\n",
    "                break\n",
    "        else:\n",
    "            # if we didn’t break, assign a new letter\n",
    "            letter_groups[m] = chr(current_letter)\n",
    "            current_letter += 1\n",
    "\n",
    "    # build a summary table\n",
    "    summary = pd.DataFrame({\n",
    "        'Mean Rank': [mean_ranks[m] for m in methods],\n",
    "        'Group':     [letter_groups[m] for m in methods]\n",
    "    }, index=methods)\n",
    "\n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "def get_summary(summary, flat):\n",
    "    # 1) Re‐group the raw AALC values by experiment (no seed)\n",
    "    exp_vals = defaultdict(list)\n",
    "    for name, aalc in flat:          # flat from your earlier code\n",
    "        exp = name.rsplit('_', 1)[0]  # drop the final \"_<seed>\"\n",
    "        exp_vals[exp].append(aalc)\n",
    "\n",
    "    # 2) Bootstrap to get mean ± 95% CI\n",
    "    n_boot = 10_000\n",
    "    rng    = np.random.default_rng(0)  # for reproducibility\n",
    "\n",
    "    boot_means = {}\n",
    "    ci_lower   = {}\n",
    "    ci_upper   = {}\n",
    "    for exp, vals in exp_vals.items():\n",
    "        arr = np.array(vals)\n",
    "        # draw B x len(arr) resamples\n",
    "        samples = rng.choice(arr, size=(n_boot, len(arr)), replace=True)\n",
    "        means   = samples.mean(axis=1)\n",
    "        boot_means[exp] = arr.mean()\n",
    "        ci_lower[exp], ci_upper[exp] = np.percentile(means, [2.5, 97.5])\n",
    "\n",
    "    # 3) Build a DataFrame and merge with your existing summary\n",
    "    ci_df = pd.DataFrame({\n",
    "        'Mean AALC': pd.Series(boot_means),\n",
    "        'CI Lower':  pd.Series(ci_lower),\n",
    "        'CI Upper':  pd.Series(ci_upper),\n",
    "    })\n",
    "\n",
    "    # suppose `summary` is your DataFrame indexed by experiment\n",
    "    # with columns like ['Mean Rank','Group',…]\n",
    "    final = summary.join(ci_df)\n",
    "\n",
    "    print(final)\n",
    "    return final\n",
    "\n",
    "def plot(final, dataset, configuration, name_plot=\"test\"):\n",
    "    # --- prepare data ---\n",
    "    # order experiments by ascending Mean Rank\n",
    "    order   = final['Mean Rank'].sort_values().index\n",
    "    df_plot = final.loc[order].reset_index().rename(columns={'index': 'Experiment'})\n",
    "\n",
    "    df_plot['Experiment'] = (\n",
    "    df_plot['Experiment']\n",
    "           .str.replace('_01', '_0.1', regex=False)\n",
    "           .str.replace('midropout', 'batchbald', regex=False)\n",
    "           .str.replace('_random', '', regex=False)\n",
    "           .str.replace('threshold', 'thresholding', regex=False)\n",
    "    )\n",
    "    \n",
    "    # extract plotting arrays\n",
    "    experiments = df_plot['Experiment']\n",
    "    means       = df_plot['Mean AALC']\n",
    "    ci_lower    = df_plot['CI Lower']\n",
    "    ci_upper    = df_plot['CI Upper']\n",
    "    # symmetric error‐bars\n",
    "    errors = [means - ci_lower, ci_upper - means]\n",
    "    groups      = df_plot['Group']\n",
    "\n",
    "    # --- assign colors by group using Set1 palette ---\n",
    "    palette = plt.get_cmap('Set1').colors\n",
    "    unique_groups  = groups.unique()\n",
    "    group_color_map = {g: palette[i % len(palette)]\n",
    "                       for i, g in enumerate(unique_groups)}\n",
    "    bar_colors     = [group_color_map[g] for g in groups]\n",
    "\n",
    "    # figure size (inches)\n",
    "    if configuration == \"area\":\n",
    "        width_in  = 2.8\n",
    "        height_in = 2.6\n",
    "    else:\n",
    "        width_in  = 2.8\n",
    "        height_in = 3.8\n",
    "\n",
    "    # global rcParams\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 8,\n",
    "        'font.family': 'serif',\n",
    "        'axes.titlesize': 8,\n",
    "        'axes.labelsize': 8,\n",
    "        'xtick.labelsize': 7,\n",
    "        'ytick.labelsize': 7,\n",
    "        'legend.fontsize': 7,\n",
    "        'text.usetex': True,\n",
    "        'font.serif': ['Times'],\n",
    "    })\n",
    "\n",
    "    # --- plotting ---\n",
    "    fig, ax = plt.subplots(figsize=(width_in, height_in))\n",
    "    ax.barh(experiments, means,\n",
    "            xerr=errors,\n",
    "            capsize=0,\n",
    "            )\n",
    "    \n",
    "    # Hide all spines except the bottom (x-axis)\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    # axis labels & limits\n",
    "    # ax.set_ylabel('Experiment')     # now vertical axis is your categories\n",
    "    ax.set_xlabel('Mean nAUC')\n",
    "\n",
    "    if dataset == \"build6k\":\n",
    "        x_lims = (0.7, 0.82)\n",
    "    else:\n",
    "        x_lims = (0.6, 0.75)\n",
    "    ax.set_xlim(x_lims)\n",
    "\n",
    "    # invert so best (lowest rank) is at top, if desired\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # ensure ticks and labels are horizontal\n",
    "    ax.xaxis.set_tick_params(rotation=0)\n",
    "    ax.yaxis.set_tick_params(rotation=0)\n",
    "    ax.tick_params(axis='x', pad=4)  # default is ~4–6\n",
    "    ax.margins(y=0.02)\n",
    "\n",
    "    # ax.set_title('build6k distance')\n",
    "\n",
    "    # # --- custom legend for Group ---\n",
    "    # legend_handles = [\n",
    "    #     mpatches.Patch(color=group_color_map[g], label=g)\n",
    "    #     for g in unique_groups\n",
    "    # ]\n",
    "    # ax.legend(handles=legend_handles, title='Group', loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name_plot, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Inputs\n",
    "    dataset = \"nieman17k\"\n",
    "    path_results = dataset + \".npy\"\n",
    "    configuration = \"area\"\n",
    "    name_plot = \"results\" + \"_\" + dataset + \"_\" + configuration + \".pdf\"\n",
    "    # (build6k [0.7, 0.82] ) (niemam17k [0.6, 0.75])\n",
    "\n",
    "    # Load the json file\n",
    "    loaded = np.load(path_results, allow_pickle=True).item()\n",
    "    print(\"loaded!\")\n",
    "\n",
    "    # Compute AALC\n",
    "    aalc_dict = compute_AALC(loaded)\n",
    "\n",
    "    # Compute rankings\n",
    "    rankings = rank_experiments(loaded, configuration)\n",
    "    for name, score in rankings:\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "    # Get average ranks\n",
    "    groups, flat = get_average_ranks_group(loaded, configuration)\n",
    "\n",
    "    # Calculate Kruskal-Wallis test\n",
    "    calculate_krusal(groups)\n",
    "\n",
    "    # Calculate Dunn's post-hoc test\n",
    "    df_adj, mean_ranks = calculate_posthoc(groups)\n",
    "\n",
    "    # Get significant categories\n",
    "    get_categories(df_adj)\n",
    "\n",
    "    # Sort methods\n",
    "    summary = sort_methods(df_adj, mean_ranks, alpha=0.05)\n",
    "\n",
    "    # Get summary\n",
    "    final = get_summary(summary, flat)\n",
    "\n",
    "    # Plot results\n",
    "    plot(final, dataset, configuration, name_plot=name_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded!\n",
      "greedy_midropout_inf_2: 0.7119\n",
      "greedy_midropout_inf_4: 0.7116\n",
      "greedy_midropout_inf_1: 0.7106\n",
      "greedy_midropout_inf_3: 0.7089\n",
      "greedy_midropout_inf_5: 0.7075\n",
      "greedy_badge_inf_1: 0.7029\n",
      "greedy_badge_inf_3: 0.6989\n",
      "greedy_badge_inf_5: 0.6953\n",
      "greedy_coreset_inf_5: 0.6947\n",
      "greedy_badge_inf_4: 0.6944\n",
      "random_random_inf_2: 0.6918\n",
      "greedy_midropout_101_5: 0.6916\n",
      "greedy_coreset_inf_4: 0.6889\n",
      "greedy_midropout_101_2: 0.6884\n",
      "greedy_midropout_101_4: 0.6883\n",
      "greedy_badge_inf_2: 0.6882\n",
      "greedy_midropout_101_3: 0.6881\n",
      "greedy_midropout_101_1: 0.6881\n",
      "greedy_coreset_inf_3: 0.6863\n",
      "random_random_inf_3: 0.6852\n",
      "random_random_inf_5: 0.6852\n",
      "random_random_inf_1: 0.6848\n",
      "greedy_coreset_inf_2: 0.6844\n",
      "greedy_badge_101_5: 0.6837\n",
      "greedy_coreset_inf_1: 0.6805\n",
      "random_random_inf_4: 0.6797\n",
      "threshold_midropout_101_1: 0.6789\n",
      "greedy_badge_101_2: 0.6785\n",
      "threshold_midropout_101_4: 0.6768\n",
      "threshold_midropout_101_3: 0.6764\n",
      "threshold_midropout_101_5: 0.6748\n",
      "random_random_101_1: 0.6737\n",
      "threshold_midropout_101_2: 0.6730\n",
      "random_random_101_2: 0.6727\n",
      "greedy_badge_101_4: 0.6718\n",
      "greedy_badge_101_1: 0.6707\n",
      "threshold_badge_101_4: 0.6706\n",
      "random_random_101_3: 0.6705\n",
      "greedy_badge_101_3: 0.6704\n",
      "threshold_badge_101_5: 0.6695\n",
      "random_random_101_4: 0.6666\n",
      "threshold_badge_101_1: 0.6659\n",
      "threshold_badge_101_2: 0.6656\n",
      "random_random_101_5: 0.6638\n",
      "threshold_badge_101_3: 0.6615\n",
      "greedy_coreset_101_2: 0.6605\n",
      "greedy_coreset_101_5: 0.6589\n",
      "threshold_coreset_101_4: 0.6563\n",
      "greedy_coreset_101_4: 0.6555\n",
      "threshold_coreset_101_1: 0.6553\n",
      "threshold_coreset_101_2: 0.6552\n",
      "greedy_coreset_101_1: 0.6552\n",
      "threshold_coreset_101_5: 0.6551\n",
      "threshold_coreset_101_3: 0.6513\n",
      "greedy_coreset_101_3: 0.6506\n",
      "=== Global ranks (experiment_seed) ===\n",
      "greedy_midropout_inf_2          aalc=0.7119, rank=1\n",
      "greedy_midropout_inf_4          aalc=0.7116, rank=2\n",
      "greedy_midropout_inf_1          aalc=0.7106, rank=3\n",
      "greedy_midropout_inf_3          aalc=0.7089, rank=4\n",
      "greedy_midropout_inf_5          aalc=0.7075, rank=5\n",
      "greedy_badge_inf_1              aalc=0.7029, rank=6\n",
      "greedy_badge_inf_3              aalc=0.6989, rank=7\n",
      "greedy_badge_inf_5              aalc=0.6953, rank=8\n",
      "greedy_coreset_inf_5            aalc=0.6947, rank=9\n",
      "greedy_badge_inf_4              aalc=0.6944, rank=10\n",
      "\n",
      "=== Average rank per experiment ===\n",
      "greedy_midropout_inf            avg_rank=3.00\n",
      "greedy_badge_inf                avg_rank=9.40\n",
      "greedy_midropout_101            avg_rank=15.20\n",
      "greedy_coreset_inf              avg_rank=17.80\n",
      "random_random_inf               avg_rank=20.00\n",
      "threshold_midropout_101         avg_rank=30.00\n",
      "greedy_badge_101                avg_rank=32.40\n",
      "random_random_101               avg_rank=37.80\n",
      "threshold_badge_101             avg_rank=41.40\n",
      "greedy_coreset_101              avg_rank=49.80\n",
      "threshold_coreset_101           avg_rank=51.20\n",
      "=== Kruskal–Wallis test ===\n",
      "Group 1 (greedy_midropout_inf): [1, 2, 3, 4, 5]\n",
      "Group 2 (greedy_badge_inf): [6, 7, 8, 10, 16]\n",
      "Group 3 (greedy_coreset_inf): [9, 13, 19, 23, 25]\n",
      "Group 4 (random_random_inf): [11, 20, 21, 22, 26]\n",
      "Group 5 (greedy_midropout_101): [12, 14, 15, 17, 18]\n",
      "Group 6 (greedy_badge_101): [24, 28, 35, 36, 39]\n",
      "Group 7 (threshold_midropout_101): [27, 29, 30, 31, 33]\n",
      "Group 8 (random_random_101): [32, 34, 38, 41, 44]\n",
      "Group 9 (threshold_badge_101): [37, 40, 42, 43, 45]\n",
      "Group 10 (greedy_coreset_101): [46, 47, 49, 52, 55]\n",
      "Group 11 (threshold_coreset_101): [48, 50, 51, 53, 54]\n",
      "\n",
      "Kruskal–Wallis H = 50.947, p = 0.000\n",
      "\n",
      "Kruskal-Wallis test: H = 50.947, p = 0.000\n",
      "\n",
      "=== Dunn's test (post-hoc) ===\n",
      "Pairwise adjusted p-values:\n",
      "                         greedy_midropout_inf  greedy_badge_inf  \\\n",
      "greedy_midropout_inf                      NaN             1.000   \n",
      "greedy_badge_inf                        1.000               NaN   \n",
      "greedy_coreset_inf                      1.000             1.000   \n",
      "random_random_inf                       1.000             1.000   \n",
      "greedy_midropout_101                    1.000             1.000   \n",
      "greedy_badge_101                        0.156             0.859   \n",
      "threshold_midropout_101                 0.308             1.000   \n",
      "random_random_101                       0.029             0.208   \n",
      "threshold_badge_101                     0.008             0.073   \n",
      "greedy_coreset_101                      0.000             0.003   \n",
      "threshold_coreset_101                   0.000             0.002   \n",
      "\n",
      "                         greedy_coreset_inf  random_random_inf  \\\n",
      "greedy_midropout_inf                  1.000              1.000   \n",
      "greedy_badge_inf                      1.000              1.000   \n",
      "greedy_coreset_inf                      NaN              1.000   \n",
      "random_random_inf                     1.000                NaN   \n",
      "greedy_midropout_101                  1.000              1.000   \n",
      "greedy_badge_101                      1.000              1.000   \n",
      "threshold_midropout_101               1.000              1.000   \n",
      "random_random_101                     1.000              1.000   \n",
      "threshold_badge_101                   0.754              1.000   \n",
      "greedy_coreset_101                    0.073              0.141   \n",
      "threshold_coreset_101                 0.046              0.091   \n",
      "\n",
      "                         greedy_midropout_101  greedy_badge_101  \\\n",
      "greedy_midropout_inf                    1.000             0.156   \n",
      "greedy_badge_inf                        1.000             0.859   \n",
      "greedy_coreset_inf                      1.000             1.000   \n",
      "random_random_inf                       1.000             1.000   \n",
      "greedy_midropout_101                      NaN             1.000   \n",
      "greedy_badge_101                        1.000               NaN   \n",
      "threshold_midropout_101                 1.000             1.000   \n",
      "random_random_101                       0.926             1.000   \n",
      "threshold_badge_101                     0.379             1.000   \n",
      "greedy_coreset_101                      0.031             1.000   \n",
      "threshold_coreset_101                   0.019             1.000   \n",
      "\n",
      "                         threshold_midropout_101  random_random_101  \\\n",
      "greedy_midropout_inf                       0.308              0.029   \n",
      "greedy_badge_inf                           1.000              0.208   \n",
      "greedy_coreset_inf                         1.000              1.000   \n",
      "random_random_inf                          1.000              1.000   \n",
      "greedy_midropout_101                       1.000              0.926   \n",
      "greedy_badge_101                           1.000              1.000   \n",
      "threshold_midropout_101                      NaN              1.000   \n",
      "random_random_101                          1.000                NaN   \n",
      "threshold_badge_101                        1.000              1.000   \n",
      "greedy_coreset_101                         1.000              1.000   \n",
      "threshold_coreset_101                      1.000              1.000   \n",
      "\n",
      "                         threshold_badge_101  greedy_coreset_101  \\\n",
      "greedy_midropout_inf                   0.008               0.000   \n",
      "greedy_badge_inf                       0.073               0.003   \n",
      "greedy_coreset_inf                     0.754               0.073   \n",
      "random_random_inf                      1.000               0.141   \n",
      "greedy_midropout_101                   0.379               0.031   \n",
      "greedy_badge_101                       1.000               1.000   \n",
      "threshold_midropout_101                1.000               1.000   \n",
      "random_random_101                      1.000               1.000   \n",
      "threshold_badge_101                      NaN               1.000   \n",
      "greedy_coreset_101                     1.000                 NaN   \n",
      "threshold_coreset_101                  1.000               1.000   \n",
      "\n",
      "                         threshold_coreset_101  \n",
      "greedy_midropout_inf                     0.000  \n",
      "greedy_badge_inf                         0.002  \n",
      "greedy_coreset_inf                       0.046  \n",
      "random_random_inf                        0.091  \n",
      "greedy_midropout_101                     0.019  \n",
      "greedy_badge_101                         1.000  \n",
      "threshold_midropout_101                  1.000  \n",
      "random_random_101                        1.000  \n",
      "threshold_badge_101                      1.000  \n",
      "greedy_coreset_101                       1.000  \n",
      "threshold_coreset_101                      NaN  \n",
      "\n",
      "=== Dunn's test (post-hoc) ===\n",
      "Pairwise adjusted p-values:\n",
      "                  Group1                 Group2     p_adj\n",
      "6   greedy_midropout_inf      random_random_101  0.029088\n",
      "7   greedy_midropout_inf    threshold_badge_101  0.007689\n",
      "8   greedy_midropout_inf     greedy_coreset_101  0.000208\n",
      "9   greedy_midropout_inf  threshold_coreset_101  0.000108\n",
      "17      greedy_badge_inf     greedy_coreset_101  0.003477\n",
      "18      greedy_badge_inf  threshold_coreset_101  0.001962\n",
      "26    greedy_coreset_inf  threshold_coreset_101  0.046038\n",
      "38  greedy_midropout_101     greedy_coreset_101  0.030641\n",
      "39  greedy_midropout_101  threshold_coreset_101  0.019048\n",
      "                         Mean Rank Group\n",
      "greedy_midropout_inf           3.0     A\n",
      "greedy_badge_inf               9.4     A\n",
      "greedy_midropout_101          15.2     A\n",
      "greedy_coreset_inf            17.8     A\n",
      "random_random_inf             20.0     A\n",
      "threshold_midropout_101       30.0     A\n",
      "greedy_badge_101              32.4     A\n",
      "random_random_101             37.8     B\n",
      "threshold_badge_101           41.4     B\n",
      "greedy_coreset_101            49.8     B\n",
      "threshold_coreset_101         51.2     B\n",
      "                         Mean Rank Group  Mean AALC  CI Lower  CI Upper\n",
      "greedy_midropout_inf           3.0     A   0.710104  0.708622  0.711495\n",
      "greedy_badge_inf               9.4     A   0.695916  0.691739  0.700360\n",
      "greedy_midropout_101          15.2     A   0.688873  0.688122  0.690233\n",
      "greedy_coreset_inf            17.8     A   0.686965  0.682947  0.691361\n",
      "random_random_inf             20.0     A   0.685339  0.681897  0.689087\n",
      "threshold_midropout_101       30.0     A   0.675999  0.674206  0.677671\n",
      "greedy_badge_101              32.4     A   0.675009  0.670785  0.680004\n",
      "random_random_101             37.8     B   0.669452  0.666125  0.672484\n",
      "threshold_badge_101           41.4     B   0.666626  0.663916  0.669218\n",
      "greedy_coreset_101            49.8     B   0.656131  0.653158  0.659097\n",
      "threshold_coreset_101         51.2     B   0.654626  0.652830  0.655863\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 280x260 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
